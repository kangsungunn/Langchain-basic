# ğŸ”„ Midm ëª¨ë¸ë¡œ ì „í™˜í•˜ê¸°

## í˜„ì¬ ìƒí™©

- **ê¸°ì¡´**: OpenAI GPT-4o-mini ì‚¬ìš© ì¤‘
- **ë³€ê²½**: ë¡œì»¬ Midm-2.0-Mini-Instruct ëª¨ë¸ë¡œ ì „í™˜

## ğŸš€ ë¹ ë¥¸ ì „í™˜ ë°©ë²•

### Docker ì‚¬ìš© ì¤‘ì¸ ê²½ìš°

```bash
# 1. Docker ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose down
docker-compose up -d

# 2. ë¡œê·¸ í™•ì¸
docker-compose logs -f langchain-app
```

### ë¡œì»¬ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export LLM_PROVIDER=local_llama
export MIDM_MODEL_PATH=app/models/midm
export MIDM_DEVICE=cpu
export OPENAI_API_KEY=your_key  # Embeddingsìš©

# 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install transformers torch langchain-huggingface accelerate

# 3. ì„œë²„ ì‹¤í–‰
uvicorn app.api_server_refactored:app --host 0.0.0.0 --port 8000 --reload
```

## âœ… ì ìš© í™•ì¸

### 1. ì„œë²„ ì‹œì‘ ë¡œê·¸ í™•ì¸

```
ğŸš€ FastAPI ì„œë²„ ì‹œì‘ ì¤‘...
ğŸ”„ ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì¤‘: app/models/midm
âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: midm-2.0-mini-instruct
   ë””ë°”ì´ìŠ¤: cpu
âœ… LLM ëª¨ë¸: midm-2.0-mini-instruct
```

### 2. API í…ŒìŠ¤íŠ¸

```bash
curl -X POST http://localhost:8000/api/chat/general \
  -H "Content-Type: application/json" \
  -d '{"message": "ì•ˆë…•í•˜ì„¸ìš”!"}'
```

### 3. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í™•ì¸

- http://localhost:3000 ì ‘ì†
- ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡
- ì‘ë‹µì˜ ì¶œì²˜ì— "midm" ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ í‘œì‹œ í™•ì¸

## ğŸ“ ë³€ê²½ ë‚´ì—­

### `docker-compose.yaml`

```yaml
environment:
  LLM_PROVIDER: local_llama        # â† OpenAIì—ì„œ ë³€ê²½
  MIDM_MODEL_PATH: app/models/midm
  MIDM_DEVICE: cpu
```

### ì„œë²„ ëª…ë ¹ì–´

```yaml
command: uvicorn api_server_refactored:app --host 0.0.0.0 --port 8000 --reload
# ì´ì „: api_server:app
```

## ğŸ”™ OpenAIë¡œ ë˜ëŒë¦¬ê¸°

```bash
# docker-compose.yaml ìˆ˜ì •
environment:
  LLM_PROVIDER: openai
  OPENAI_API_KEY: ${OPENAI_API_KEY}

# ì¬ì‹œì‘
docker-compose restart langchain-app
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì²« ì‹¤í–‰ ì‹œê°„**: Midm ëª¨ë¸ ë¡œë“œì— 30ì´ˆ~1ë¶„ ì†Œìš”
2. **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM í•„ìš”
3. **ì†ë„**: CPU ì‚¬ìš© ì‹œ ì‘ë‹µì´ ëŠë¦´ ìˆ˜ ìˆìŒ (GPU ê¶Œì¥)
4. **Embeddings**: ë²¡í„° ê²€ìƒ‰ì€ ì—¬ì „íˆ OpenAI Embeddings ì‚¬ìš©

## ğŸ› ë¬¸ì œ í•´ê²°

### ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨

```bash
# transformers ì„¤ì¹˜ í™•ì¸
pip install transformers torch langchain-huggingface

# ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh app/models/midm/
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# 8-bit ì–‘ìí™” ì‚¬ìš©
# app/models/providers/local_llama_provider.py ìˆ˜ì •
load_in_8bit=True
```

### ë„ˆë¬´ ëŠë¦¼

```bash
# GPU ì‚¬ìš©
export MIDM_DEVICE=cuda
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | OpenAI | Midm (CPU) | Midm (GPU) |
|------|--------|------------|------------|
| ì‘ë‹µ ì†ë„ | ë¹ ë¦„ (1-2ì´ˆ) | ëŠë¦¼ (10-30ì´ˆ) | ë³´í†µ (3-5ì´ˆ) |
| ë¹„ìš© | ìœ ë£Œ | ë¬´ë£Œ | ë¬´ë£Œ |
| í’ˆì§ˆ | ë§¤ìš° ë†’ìŒ | ë³´í†µ | ë³´í†µ |
| ì¸í„°ë„· | í•„ìš” | ë¶ˆí•„ìš” | ë¶ˆí•„ìš” |

